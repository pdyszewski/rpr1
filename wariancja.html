<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>13 Wariancja | Rachunek Prawdopodobieństwa 1R</title>
<meta name="author" content="Dariusz Buraczewski">
<meta name="author" content="Piotr Dyszewski">
<meta name="description" content="Dla zmiennej losowej \(X\) jej wartość oczekiwana \(\mathbb{E}[X]\) jest średnią ważoną. W niektórych przypadkach, kiedy zmienna \(X\) jest skomplikowana, aby wydobyć jakiekolwiek ilościowe...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="13 Wariancja | Rachunek Prawdopodobieństwa 1R">
<meta property="og:type" content="book">
<meta property="og:description" content="Dla zmiennej losowej \(X\) jej wartość oczekiwana \(\mathbb{E}[X]\) jest średnią ważoną. W niektórych przypadkach, kiedy zmienna \(X\) jest skomplikowana, aby wydobyć jakiekolwiek ilościowe...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="13 Wariancja | Rachunek Prawdopodobieństwa 1R">
<meta name="twitter:description" content="Dla zmiennej losowej \(X\) jej wartość oczekiwana \(\mathbb{E}[X]\) jest średnią ważoną. W niektórych przypadkach, kiedy zmienna \(X\) jest skomplikowana, aby wydobyć jakiekolwiek ilościowe...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.8.0/transition.js"></script><script src="libs/bs3compat-0.8.0/tabs.js"></script><script src="libs/bs3compat-0.8.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.0/p5.js"></script><script src="https://cdn.jsdelivr.net/npm/quizdown@latest/public/build/quizdown.js">
    	</script><script>quizdown.init();</script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
<link rel="stylesheet" href="java.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Notatki do wykładu">Rachunek Prawdopodobieństwa 1R</a>:
        <small class="text-muted">Notatki do wykładu</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"></a></li>
<li><a class="" href="sylabus.html">Sylabus</a></li>
<li class="book-part">Notatki</li>
<li><a class="" href="wprowadzenie.html"><span class="header-section-number">1</span> Wprowadzenie</a></li>
<li><a class="" href="aksjomatyka-rachunku-prawdopodobie%C5%84stwa.html"><span class="header-section-number">2</span> Aksjomatyka rachunku prawdopodobieństwa</a></li>
<li><a class="" href="prawdopodobie%C5%84stwo-warunkowe.html"><span class="header-section-number">3</span> Prawdopodobieństwo warunkowe</a></li>
<li><a class="" href="niezale%C5%BCno%C5%9B%C4%87-zdarze%C5%84.html"><span class="header-section-number">4</span> Niezależność zdarzeń</a></li>
<li><a class="" href="lemat-borela-cantellego.html"><span class="header-section-number">5</span> Lemat Borela-Cantellego</a></li>
<li><a class="" href="zmienne-losowe-i-ich-rozk%C5%82ady.html"><span class="header-section-number">6</span> Zmienne losowe i ich rozkłady</a></li>
<li><a class="" href="warto%C5%9B%C4%87-oczekiwana-definicja-i-w%C5%82asno%C5%9Bci.html"><span class="header-section-number">7</span> Wartość oczekiwana: definicja i własności</a></li>
<li><a class="" href="warto%C5%9B%C4%87-oczekiwana-zastosowania.html"><span class="header-section-number">8</span> Wartość oczekiwana: zastosowania</a></li>
<li><a class="" href="przegl%C4%85d-wa%C5%BCniejszych-rozk%C5%82ad%C3%B3w.html"><span class="header-section-number">9</span> Przegląd ważniejszych rozkładów</a></li>
<li><a class="" href="wektory-losowe.html"><span class="header-section-number">10</span> Wektory losowe</a></li>
<li><a class="" href="rozk%C5%82ady-warunkowe.html"><span class="header-section-number">11</span> Rozkłady warunkowe</a></li>
<li><a class="" href="niezale%C5%BCne-zmienne-losowe.html"><span class="header-section-number">12</span> Niezależne zmienne losowe</a></li>
<li><a class="active" href="wariancja.html"><span class="header-section-number">13</span> Wariancja</a></li>
<li><a class="" href="kowariancja.html"><span class="header-section-number">14</span> Kowariancja</a></li>
<li class="book-part">Listy zadań</li>
<li><a class="" href="lista-1-rozgrzewka.html">Lista 1: Rozgrzewka</a></li>
<li><a class="" href="lista-2-aksjomaty-rachunku-prawdopodobie%C5%84stwa.html">Lista 2: Aksjomaty rachunku prawdopodobieństwa</a></li>
<li><a class="" href="lista-3-prawdopodobie%C5%84stwo-warunkowe.html">Lista 3: Prawdopodobieństwo warunkowe</a></li>
<li><a class="" href="lista-4-niezale%C5%BCno%C5%9B%C4%87-i-lemat-borela-cantellego.html">Lista 4: Niezależność i lemat Borela-Cantellego</a></li>
<li><a class="" href="lista-5-zmienne-losowe.html">Lista 5: Zmienne losowe</a></li>
<li><a class="" href="lista-6-warto%C5%9B%C4%87-oczekiwana.html">Lista 6: Wartość oczekiwana</a></li>
<li><a class="" href="lista-7-powt%C3%B3rka-przed-kolokwium.html">Lista 7: Powtórka przed kolokwium</a></li>
<li><a class="" href="lista-8-wektory-losowe.html">Lista 8: wektory losowe</a></li>
<li><a class="" href="lista-9-niezale%C5%BCne-zmienne.html">Lista 9: Niezależne zmienne</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="wariancja" class="section level1" number="13">
<h1>
<span class="header-section-number">13</span> Wariancja<a class="anchor" aria-label="anchor" href="#wariancja"><i class="fas fa-link"></i></a>
</h1>
<p>Dla zmiennej losowej <span class="math inline">\(X\)</span> jej wartość oczekiwana <span class="math inline">\(\mathbb{E}[X]\)</span> jest średnią ważoną.
W niektórych przypadkach, kiedy zmienna <span class="math inline">\(X\)</span> jest skomplikowana,
aby wydobyć jakiekolwiek ilościowe informacje o <span class="math inline">\(X\)</span>,
zmuszeni jesteśmy przybliżać <span class="math inline">\(X\)</span> przez jej średnią <span class="math inline">\(\mathbb{E}[X]\)</span>.
Chcielibyśmy wtedy wiedzieć jaki jest bład takiego przybliżenia.
Do tego będzie nam służyła wariancja.
Wariancję będziemy definiować dla zmiennych losowych, które są dostatecznie regularne.</p>
<div class="definition">
<p><span id="def:unlabeled-div-133" class="definition"><strong>Definicja 13.1  </strong></span>Powiemy, że zmienna losowa <span class="math inline">\(X\)</span> jest całkowalna z kwadratem, jeżeli
<span class="math inline">\(\mathbb{E}\left[X^2 \right]&lt;\infty\)</span>.</p>
</div>
<p>Przypomnijmy, że funkcja <span class="math inline">\(\varphi \colon \mathbb{R} \to \mathbb{R}\)</span> jest wypukła,
jeżeli dla każdych <span class="math inline">\(x, y \in \mathbb{R}\)</span> oraz <span class="math inline">\(\alpha \in (0,1)\)</span>
<span class="math display" id="eq:con">\[\begin{equation}
    \varphi(\alpha x +(1-\alpha)y) \leq \alpha \varphi(x) +(1-\alpha)\varphi(y).
    \tag{13.1}
\end{equation}\]</span>
Geometrycznie powyższy warunek oznacza, że odcinek łączący dwa punkty na wykresie <span class="math inline">\((x, \varphi(x))\)</span>
oraz <span class="math inline">\((y, \varphi(y))\)</span> leży w całości ponad wykresem.</p>
<div style="margin:2px; padding:1px; text-align:center;">
<div class="inline-figure"><img src="TIKZ/convex.svg" style="display: block; margin: auto;"></div>
</div>
<div class="lemma">
<p><span id="lem:unlabeled-div-134" class="lemma"><strong>Lemma 13.1  (Nierówność Jensena) </strong></span>Niech <span class="math inline">\(X\)</span> będzie zmienną losową taką, że <span class="math inline">\(\varphi(X)\)</span> ma wartość oczekiwaną dla
pewnej wypukłej funkcji <span class="math inline">\(\varphi \colon \mathbb{R} \to \mathbb{R}\)</span>. Wówczas
<span class="math display">\[\begin{equation*}
    \varphi\left( \mathbb{E} [X] \right) \leq \mathbb{E}\left[ \varphi(X) \right].
\end{equation*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-135" class="proof"><em>Proof</em>. </span>Pozostawiamy jako zadanie.</p>
</div>
<p>Zauważmy, że jeżeli <span class="math inline">\(\mathbb{P}[X=x] =\alpha\)</span> i <span class="math inline">\(\mathbb{P}[X=y]=1-\alpha\)</span>, to
nierówność Jensena sprowadza się do <a href="wariancja.html#eq:con">(13.1)</a>.
Rzeczywiście, mamy
<span class="math display">\[\begin{align*}
    \mathbb{E}[X] &amp; = x \mathbb{P}[X=x] +y\mathbb{P}[X=y] \\ &amp;= x\alpha+y(1-\alpha).
\end{align*}\]</span>
Stąd
<span class="math display">\[\begin{equation*}
    \varphi\left(\mathbb{E}[X] \right) = \varphi(\alpha x +(1-\alpha)y)
\end{equation*}\]</span>
jest nie większe niż
<span class="math display">\[\begin{align*}
    \mathbb{E}\left[\varphi(X)\right] &amp;= \varphi(x) \mathbb{P}[X=x] +\varphi(y)\mathbb{P}[X=y]
    \\&amp;= \varphi(x)\alpha+\varphi(y)(1-\alpha).
\end{align*}\]</span></p>
<p>Przypomnijmy, że jeżeli funkcja <span class="math inline">\(\varphi\)</span> jest dwukrotnie różniczkowalna,
to jest ona wypukła wtedy i tylko wtedy, gdy <span class="math inline">\(\varphi''(x) \geq 0\)</span>
dla wszystkich <span class="math inline">\(x \in \mathbb{R}\)</span>.</p>
<p>Zauważmy, że stosując nierówność Jensana do funkcji wypukłej <span class="math inline">\(\varphi(x)=x^2\)</span> otrzymujemy
<span class="math display">\[\begin{equation*}
    \mathbb{E}[|X|]^2 \leq \mathbb{E}\left[X^2 \right].
\end{equation*}\]</span>
Oznacza to, że każda zmienna całkowalna z kwadratem posiada wartość oczekiwaną.</p>
<div class="definition">
<p><span id="def:unlabeled-div-136" class="definition"><strong>Definicja 13.2  </strong></span>Niech <span class="math inline">\(X\)</span> będzie zmienną losową całkowalną z kwadratem. Liczbę
<span class="math display">\[\mathbb{V}ar  [X] =\mathbb{E}[X-\mathbb{E} [X]]^2
  \]</span> nazywamy <strong>wariancją</strong> zmiennej losowej <span class="math inline">\(X\)</span>.</p>
<p>Pierwiastek z wariancji nazywamy <strong>odchyleniem standardowym</strong>
<span class="math display">\[
  \sigma_X =  \sqrt{\mathbb{V}ar[ X]}.
  \]</span></p>
</div>
<p>Wartość oczekiwana odpowiada średniej wartości,
a wariancja opisuje odchylenie od wartości oczekiwanej.
Dla przykładu instytucje finansowe
opisując inwestycję podają dwa kluczowe parametry:
stopę zwrotu (wartość oczekiwaną zysku) oraz ryzyko (odchylenie standardowe).
Celem inwestycji jest taki dobór instrumentów,
aby przy określonej stopie zwrotu zminimalizować ryzyko.</p>
<div class="example">
<p><span id="exm:unlabeled-div-137" class="example"><strong>Przykład 13.1  </strong></span>Przypuśćmy, że właśnie otrzymaliśmy propozycję nie do odrzucenia;
ktoś podarował nam dwa losy na pewną loterię.
Organizatorzy loterii sprzedają <span class="math inline">\(100\)</span> losów na cotygodniowe losowanie.
Każdy z losów jest wybierany w jednorodnym procesie losowym, to znaczy, że każdy los może być
wybrany z takim samym prawdopodobieństwem — i szczęśliwy
właściciel wybranego losu wygrywa sto milionów dolarów.
Pozostałe <span class="math inline">\(99\)</span> losów nic nie wygrywa.</p>
<p>Możemy teraz wykorzystać nasz prezent na dwa sposoby: albo kupujemy dwa losy na to samo losowanie,
albo kupimy po jednym losie na dwa różne losowanie.
Która strategia jest lepsza? Spróbujmy to przeanalizować
przy użyciu zmiennych losowych <span class="math inline">\(X_1\)</span> i <span class="math inline">\(X_2\)</span>
odpowiadających wysokości wygranej dla pierwszego i dla drugiego losu.
Wartość oczekiwana <span class="math inline">\(X_1\)</span>, w milionach, wynosi
<span class="math display">\[
\mathbb{E}[X_1] = \frac{99}{100} \cdot 0 + \frac{1}{100} \cdot 100 = 1
\]</span>
i jest taka sama dla <span class="math inline">\(X_2\)</span>. Wartości oczekiwane są addytywne,
tak więc średnia całkowita wygrana (w milionach) wynosi
<span class="math display">\[
\mathbb{E}[X_1 + X_2] = \mathbb{E}[X_1] + \mathbb{E}[X_2] = 2,
\]</span>
niezależnie od tego, jaką strategię wybierzemy.
Mimo to obydwie strategie wyglądają różnie.
Nie patrzmy jednak na wartości oczekiwane i
przeanalizujmy dokładnie rozkład zmiennej losowej <span class="math inline">\(X_1 + X_2\)</span>:</p>
<div style="text-align: center;">
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th></th>
<th>wygrana</th>
<th></th>
<th></th>
</tr></thead>
<tbody>
<tr class="odd">
<td></td>
<td>0</td>
<td>100</td>
<td>200</td>
</tr>
<tr class="even">
<td>to samo losowanie</td>
<td>0,9800</td>
<td>0,0200</td>
<td></td>
</tr>
<tr class="odd">
<td>różne losowania</td>
<td>0,9801</td>
<td>0,0198</td>
<td>0,0001</td>
</tr>
</tbody>
</table></div>
</div>
<p>Gdy kupimy dwa losy na tej samej loterii,
wówczas mamy <span class="math inline">\(98\%\)</span> szansy przegranej i <span class="math inline">\(2\%\)</span> szansy wygrania <span class="math inline">\(100\)</span> milionów dolarów.
Jeśli kupimy je na różne losowania, to mamy <span class="math inline">\(98,01\%\)</span> szansy przegranej,
czyli odrobinę więcej niż poprzednio; mamy <span class="math inline">\(0,01\%\)</span> szansy wygrania <span class="math inline">\(200\)</span> milionów dolarów,
co jest również troszkę więcej niż poprzednio, i nasze szanse na wygranie <span class="math inline">\(100\)</span> milionów dolarów wynoszą teraz <span class="math inline">\(1,98\%\)</span>.
Tak więc rozkład <span class="math inline">\(X_1 + X_2\)</span> w drugim przypadku jest bardziej rozproszony:
wartość oczekiwana, <span class="math inline">\(100\)</span> milionów dolarów, jest mniej prawdopodobna,
ale wartości ekstremalne są odrobinę bardziej prawdopodobne.</p>
<p>Wariancja ma służyć właśnie do analizy pojęcia rozproszenia zmiennej losowej.
Mierzymy rozproszenie jako kwadrat odchylenia zmiennej losowej
od jej wartości oczekiwanej. W przypadku 1 wariancja wynosi
<span class="math display">\[\begin{align*}
&amp; 0{,}98(0M - 2M)^2 + 0{,}02(100M - 2M)^2 \\&amp;= 196M^2,
\end{align*}\]</span>
a w przypadku <span class="math inline">\(2\)</span>,
<span class="math display">\[\begin{align*}
&amp; 0{,}9801(0M - 2M)^2 + 0{,}0198(100M - 2M)^2 \\ &amp; + 0{,}0001(200M - 2M)^2 \\&amp;= 198M^2.
\end{align*}\]</span>
Tak jak oczekiwaliśmy,
druga wariancja jest odrobinę większa,
ponieważ rozkład losowy w przypadku <span class="math inline">\(2\)</span> jest odrobinę bardziej rozproszony.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-138" class="example"><strong>Przykład 13.2  </strong></span>Rozważmy jeszcze jeden przykład o podobnej naturze.
Student w trakcie roku ma do zaliczenia dwa kolokwia. Procentowy wynik
każdego kolokwium jest jednostajnie rozłożony na odcinku <span class="math inline">\([0,1]\)</span>.
Wyniki obu sprawdzianów są od siebie niezależne.
Jeżeli przez <span class="math inline">\(U_1\)</span> i <span class="math inline">\(U_2\)</span> oznaczymy wyniki w odpowiednio pierwszym i
drugim kolokwium, to końcowa ocena studenta
jest wyliczona na podstawie wyniku
<span class="math display">\[
    X=U_1+U_2,
\]</span>
Średni wynik z obu sprawdzianów to <span class="math inline">\(\mathbb{E}[X]=1\)</span>.
Pewien student nie mógł przystąpić do pierwszego kolokwium,
wobec czego prowadzący postanowił przeskalować wynik z pierwszego kolokwium.
Czy jest to rozwiązanie korzystne dla studenta? Wówczas ocena jest wyliczana na podstawie
wyniku
<span class="math display">\[
    Y=2U_2
\]</span>
Ze średnim wynikiem <span class="math inline">\(\mathbb{E}[Y]=1\)</span>.
Aby dokładniej przeanalizować obie możliwości zauważmy, że
<span class="math display">\[\begin{equation*}
\mathbb{V}ar[Y] = \int_0^1 (2x-1)^2 \mathrm{d}x=4/3.
\end{equation*}\]</span>
Aby policzyć wariancję zmiennej <span class="math inline">\(X\)</span> przypomnijmy, że ma ona gęstość zadaną przez
<span class="math display">\[\begin{equation*}
f_X(x) = x \mathbf{1}_{[0,1]}(x) + (2-x)\mathbf{1}_{(1,2]}(x).
\end{equation*}\]</span>
Stąd
<span class="math display">\[\begin{align*}
\mathbb{V}ar[X] =&amp; \int_0^1 (x-1)^2 x \mathrm{d}x \\ &amp;+\int_1^2(1-x)^2(2-x) \mathrm{d}x =2/3.
\end{align*}\]</span>
Rozwiązanie zaproponowane przez prowadzącego ma istotnie większą wariancję. Sugeruje to, że
w przypadku przeskalowania wyniku drugiego kolokwium ostateczny wynik jest bardziej rozproszony.
Wydać to też na symulacjach.</p>
</div>
Jeżeli wylosujemy sto wyników dla dwóch różnych sprawdzianów (<span class="math inline">\(X\)</span>)
<div style="margin:20px; padding:10px; text-align:center;">
<div class="inline-figure"><img src="TIKZ/unif5.svg" style="display: block; margin: auto;"></div>
</div>
to widzimy, że wyniki mają tendencje do koncentrowania się w połowie przedziału..
Jeżeli po prostu przeskalujemy wynik drugiego kolokwium (<span class="math inline">\(Y\)</span>), to
wyniki układają się równomiernie.
<div style="margin:20px; padding:10px; text-align:center;">
<div class="inline-figure"><img src="TIKZ/unif4.svg" style="display: block; margin: auto;"></div>
</div>
<p>Powodem jest to, że rozkład <span class="math inline">\(Y\)</span> dopuszcza wartości ekstremalne z większym prawdopodobieństwem.
Rzeczywiście, zauważmy, że <span class="math inline">\(Y\)</span> ma rozkład o gęstości <span class="math inline">\(f_Y(x) = \mathbf{1}_{[0,2]}(x)/2\)</span>.</p>
<div style="margin:20px; padding:10px; text-align:center;">
<div class="inline-figure"><img src="TIKZ/tri.svg" style="display: block; margin: auto;"></div>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-139" class="theorem"><strong>Twierdzenie 13.1  </strong></span>Niech <span class="math inline">\(X\)</span> i <span class="math inline">\(Y\)</span> będą zmiennymi losowymi takimi, że <span class="math inline">\(\mathbb{E} [X^2]\)</span>,<span class="math inline">\(\mathbb{E}[Y^2] &lt;\infty\)</span>.
Wówczas</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\mathbb{V}ar[ X] &lt;\infty\)</span></li>
<li><span class="math inline">\(\mathbb{V}ar[ X] = \mathbb{E} [X^2] - (\mathbb{E} [X])^2\)</span></li>
<li><span class="math inline">\(\mathbb{V}ar[ X ]\ge 0\)</span></li>
<li><span class="math inline">\(\mathbb{V}ar[aX] = a^2\mathbb{V}ar[X]\)</span></li>
<li><span class="math inline">\(\mathbb{V}ar[X+a] = \mathbb{V}ar[X]\)</span></li>
<li>
<span class="math inline">\(\mathbb{V}ar[ X] = 0\)</span> wtedy i tylko wtedy, gdy <span class="math inline">\(X\)</span> jest stałe z prawdopodobieństwem jeden</li>
<li>Jeżeli <span class="math inline">\(X\)</span> i <span class="math inline">\(Y\)</span> są niezależne, to <span class="math inline">\(\mathbb{V}ar[X+Y] = \mathbb{V}ar[X] + \mathbb{V}ar[Y]\)</span>
</li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-140" class="proof"><em>Proof</em>. </span>Punkty 1 pokazaliśmy już wyżej. Punkt 2. wynika z rachunku
<span class="math display">\[\begin{align*}
    \mathbb{V}ar[X] &amp; = \mathbb{E}\left[X^2 -2X\mathbb{E}[X] + \mathbb{E}[X]^2\right]\\
    &amp; = \mathbb{E}\left[X^2 \right] - 2 \mathbb{E}\left[X\mathbb{E}[X] \right] + \mathbb{E}[X]^2\\
    &amp; = \mathbb{E}\left[X^2 \right] - \mathbb{E}[X]^2.
\end{align*}\]</span>
Dowód punktów 3-6 pozostawiamy jako ćwiczenie.
Punkt 7 wynika z punktu 2:
<span class="math display">\[\begin{align*}
\mathbb{V}ar(X+Y)   = &amp;   \mathbb{E}\left[ (X+Y)^2 \right] - \mathbb{E}[X + Y]^2\\
     = &amp; \mathbb{E}[X^2] + 2 \mathbb{E}[XY] + \mathbb{E} [Y^2]  \\ &amp;- (\mathbb{E}[X]^2 +
    2\mathbb{E}[X] \cdot \mathbb{E} [Y] +\mathbb{E}[ Y]^2)\\
   = &amp; \mathbb{E}[ X^2]  - (\mathbb{E}[X]^2  + \mathbb{E} [Y^2] \\
   &amp;- (\mathbb{E}[Y])^2  = \mathbb{V}ar[ X] + \mathbb{V}ar[ Y].
\end{align*}\]</span>
<span style="display: inline-block; width: 100%; text-align: right;">□</span></p>
</div>
<p>Jeżeli <span class="math inline">\(X\)</span> ma rozkład dyskretny zadany przez
<span class="math inline">\(\mathbb{P}[X=x_i] = p_i\)</span>, <span class="math inline">\(m = \mathbb{E} [X]\)</span>, to
<span class="math display">\[\begin{align*}
\mathbb{V}ar[ X] &amp; = \sum_i p_i (x_i - m)^2  \\ &amp;= \sum_i  x_i^2p_i - m^2
\end{align*}\]</span>
Jeżeli natomiast <span class="math inline">\(X\)</span> ma rozkład absolutnie ciągły z gęstością <span class="math inline">\(g\)</span> i <span class="math inline">\(m = \mathbb{E}[X]\)</span>, to
<span class="math display">\[\begin{align*}
\mathbb{V}ar [X]  &amp; = \int_\mathbb{R} (x-m)^2 g(x)\mathrm{d}x \\
&amp; = \int_\mathbb{R} x^2 g(x)\mathrm{d}x - m^2.
\end{align*}\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-141" class="example"><strong>Przykład 13.3  </strong></span>Załóżmy, że zmienna losowa <span class="math inline">\(X\)</span> ma rozkład geometryczny z parametrem <span class="math inline">\(p&gt;0\)</span>
(<span class="math inline">\(X\sim{\rm Geom}(p)\)</span>), tzn. <span class="math inline">\(\mathbb{P}[X=k] = p(1-p)^{k-1}\)</span>, dla <span class="math inline">\(k\in \mathbb{N}\)</span>.
Przypomnijmy, że <span class="math inline">\(X\)</span> oznacza moment pierwszego sukcesu w nieskończonym schemacie Bernoulliego.
Ile wynosi <span class="math inline">\(\mathbb{V}ar[X]\)</span>?
Dla dowolnych <span class="math inline">\(p, q \in (0,1)\)</span> mamy
<span class="math display">\[\begin{align*}
    \sum_{k=0}^\infty q^kp &amp; = \frac{p}{1-q}\\
    \sum_{k=0}^\infty k q^{k-1}p &amp; = \frac{p}{(1-q)^2}\\
    \sum_{k=0}^\infty k(k-1) q^{k-2}p &amp; = \frac{2p}{(1-q)^3}\\
    \sum_{k=0}^\infty k(k-1) q^{k-1}p &amp; = \frac{2pq}{(1-q)^3}.
\end{align*}\]</span>
Jeżeli podstawimy <span class="math inline">\(q=1-p\)</span>, to druga i czwarta równość dają
<span class="math display">\[\begin{align*}
    \mathbb{E}[X]&amp; = \sum_{k=0}^\infty k q^{k-1}p  = \frac{p}{(1-q)^2}=\frac 1p\\
    \mathbb{E}[X(X-1)] &amp; = \sum_{k=0}^\infty k(k-1) q^{k-1}p  = \frac{2pq}{(1-q)^3} \\ &amp;=
    \frac{2(1-p)}{p^2}
\end{align*}\]</span>
Wówczas
<span class="math display">\[\begin{align*}
   \mathbb{V}ar[ X] &amp;  = \mathbb{E}\left[X^2\right] - \mathbb{E}[X]^2 \\ &amp;=
   \mathbb{E}[X(X-1)] +\mathbb{E}[X] -\mathbb{E}[X]^2
   \\ &amp; = \frac{1-p}{p^2}
\end{align*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-142" class="example"><strong>Przykład 13.4  </strong></span>Jeżeli <span class="math inline">\(X\sim \mathrm{Bin}(n,p)\)</span>
(<span class="math inline">\(X\)</span> ma rozkład dwumianowy z parametrami <span class="math inline">\(n,p\)</span>), to <span class="math inline">\(X\)</span> możemy przestawić
w postaci <span class="math inline">\(X = X_1+\ldots + X_n\)</span>, gdzie
<span class="math display">\[X_i = \left\{\begin{array}{cc}
                 1 &amp; \mbox{ w $i$-tym doświadczeniu jest sukces  } \\
                 0 &amp; \mbox{ w $i$-tym doświadczeniu jest porażka }
               \end{array}
\right.
\]</span>
Zmienne <span class="math inline">\(X_i\)</span> są niezależne oraz
<span class="math display">\[\begin{align*}
\mathbb{E} X_i &amp; = p,\\
\mathbb{V}ar[ X_i] &amp; = \mathbb{E} \left[X_i^2\right] - (\mathbb{E} X_i)^2
\\ &amp;= \mathbb{E} [X_i] - p^2 = p(1-p).
\end{align*}\]</span>
Zatem z powyższego twierdzenia
<span class="math display">\[\begin{align*}
  \mathbb{E} [X] &amp; = \sum_{i=1}^n \mathbb{E} [X_i] = np\\
  \mathbb{V}ar[ X] &amp; = \sum_{i=1}^n \mathbb{V}ar [X_i] = np(1-p)
\end{align*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-143" class="example"><strong>Przykład 13.5  </strong></span>Jeżeli <span class="math inline">\(X\sim \mathcal{N}(m,\sigma^2)\)</span> (zmienna losowa <span class="math inline">\(X\)</span> ma rozkład normalny z
parametrami <span class="math inline">\(m, \sigma^2\)</span>), to
<span class="math display">\[\begin{align*}
  \mathbb{E} X &amp; =
  \frac{1}{\sqrt{2\pi}\sigma} \int_\mathbb{R} x e^{-\frac{(x-m)^2}{2\sigma^2}} \mathrm{d}x
  \\ &amp; \overset{ y=(x-m)/\sigma}{ =} \frac{1}{\sqrt{2\pi}} \int_\mathbb{R} (\sigma y + m )
  e^{-y^2/2} \mathrm{d}y = m
\end{align*}\]</span>
oraz
<span class="math display">\[\begin{align*}
  \mathbb{V}ar[ X] =&amp;  \mathbb{E}(X-m)^2  
  \\ =&amp;  \frac{1}{\sqrt{2\pi}\sigma} \int_\mathbb{R} (x-m)^2 e^{-\frac{(x-m)^2}{2\sigma^2}} \mathrm{d}x\\
  &amp;\overset{ y=(x-m)/\sigma}{ =} \frac{1}{\sqrt{2\pi}} \int_\mathbb{R} \sigma^2 y^2   e^{-y^2/2} \mathrm{d}y \\
  =&amp;\frac{\sigma^2}{\sqrt{2\pi}}\big( -y e^{-\frac{y^2}2} \big)\Big|_{-\infty}^{+\infty}
   \\ &amp;+ \frac{\sigma^2}{\sqrt{2\pi}} \int_\mathbb{R} e^{-y^2/2}\mathrm{d}y = \sigma^2.
\end{align*}\]</span></p>
</div>

</div>
  <div class="chapter-nav">
<div class="prev"><a href="niezale%C5%BCne-zmienne-losowe.html"><span class="header-section-number">12</span> Niezależne zmienne losowe</a></div>
<div class="next"><a href="kowariancja.html"><span class="header-section-number">14</span> Kowariancja</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li><a class="nav-link" href="#wariancja"><span class="header-section-number">13</span> Wariancja</a></li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Rachunek Prawdopodobieństwa 1R</strong>: Notatki do wykładu" was written by Dariusz Buraczewski, Piotr Dyszewski. It was last built on 2025-04-24.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
