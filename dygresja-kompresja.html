<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>22 Dygresja: kompresja | Rachunek Prawdopodobieństwa 1R</title>
<meta name="author" content="Dariusz Buraczewski">
<meta name="author" content="Piotr Dyszewski">
<meta name="description" content="22.1 Wprowadzenie Załóżmy, że dysponujemy następującym słownikiem \[\begin{equation*}   \mathcal{A} = \{a,b,c,d,e,f,g,h\}. \end{equation*}\] Wówczas każdą wiadomość złożoną z jednego słowa możemy...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="22 Dygresja: kompresja | Rachunek Prawdopodobieństwa 1R">
<meta property="og:type" content="book">
<meta property="og:description" content="22.1 Wprowadzenie Załóżmy, że dysponujemy następującym słownikiem \[\begin{equation*}   \mathcal{A} = \{a,b,c,d,e,f,g,h\}. \end{equation*}\] Wówczas każdą wiadomość złożoną z jednego słowa możemy...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="22 Dygresja: kompresja | Rachunek Prawdopodobieństwa 1R">
<meta name="twitter:description" content="22.1 Wprowadzenie Załóżmy, że dysponujemy następującym słownikiem \[\begin{equation*}   \mathcal{A} = \{a,b,c,d,e,f,g,h\}. \end{equation*}\] Wówczas każdą wiadomość złożoną z jednego słowa możemy...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.0/p5.js"></script><script src="https://cdn.jsdelivr.net/npm/quizdown@latest/public/build/quizdown.js">
    	</script><script>quizdown.init();</script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
<link rel="stylesheet" href="java.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Notatki do wykładu">Rachunek Prawdopodobieństwa 1R</a>:
        <small class="text-muted">Notatki do wykładu</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"></a></li>
<li><a class="" href="sylabus.html">Sylabus</a></li>
<li class="book-part">Notatki</li>
<li><a class="" href="wprowadzenie.html"><span class="header-section-number">1</span> Wprowadzenie</a></li>
<li><a class="" href="aksjomatyka-rachunku-prawdopodobie%C5%84stwa.html"><span class="header-section-number">2</span> Aksjomatyka rachunku prawdopodobieństwa</a></li>
<li><a class="" href="prawdopodobie%C5%84stwo-warunkowe.html"><span class="header-section-number">3</span> Prawdopodobieństwo warunkowe</a></li>
<li><a class="" href="niezale%C5%BCno%C5%9B%C4%87-zdarze%C5%84.html"><span class="header-section-number">4</span> Niezależność zdarzeń</a></li>
<li><a class="" href="lemat-borela-cantellego.html"><span class="header-section-number">5</span> Lemat Borela-Cantellego</a></li>
<li><a class="" href="zmienne-losowe-i-ich-rozk%C5%82ady.html"><span class="header-section-number">6</span> Zmienne losowe i ich rozkłady</a></li>
<li><a class="" href="warto%C5%9B%C4%87-oczekiwana-definicja-i-w%C5%82asno%C5%9Bci.html"><span class="header-section-number">7</span> Wartość oczekiwana: definicja i własności</a></li>
<li><a class="" href="warto%C5%9B%C4%87-oczekiwana-zastosowania.html"><span class="header-section-number">8</span> Wartość oczekiwana: zastosowania</a></li>
<li><a class="" href="przegl%C4%85d-wa%C5%BCniejszych-rozk%C5%82ad%C3%B3w.html"><span class="header-section-number">9</span> Przegląd ważniejszych rozkładów</a></li>
<li><a class="" href="wektory-losowe.html"><span class="header-section-number">10</span> Wektory losowe</a></li>
<li><a class="" href="rozk%C5%82ady-warunkowe.html"><span class="header-section-number">11</span> Rozkłady warunkowe</a></li>
<li><a class="" href="niezale%C5%BCne-zmienne-losowe.html"><span class="header-section-number">12</span> Niezależne zmienne losowe</a></li>
<li><a class="" href="wariancja.html"><span class="header-section-number">13</span> Wariancja</a></li>
<li><a class="" href="kowariancja.html"><span class="header-section-number">14</span> Kowariancja</a></li>
<li><a class="" href="regresja-liniowa.html"><span class="header-section-number">15</span> Regresja liniowa</a></li>
<li><a class="" href="parametry-wielowymiarowe.html"><span class="header-section-number">16</span> Parametry wielowymiarowe</a></li>
<li><a class="" href="nier%C3%B3wno%C5%9Bci.html"><span class="header-section-number">17</span> Nierówności</a></li>
<li><a class="" href="rodzaje-zbie%C5%BCno%C5%9Bci-zmiennych-losowych.html"><span class="header-section-number">18</span> Rodzaje zbieżności zmiennych losowych</a></li>
<li><a class="" href="prawo-0-1-ko%C5%82mogorowa.html"><span class="header-section-number">19</span> Prawo \(0-1\) Kołmogorowa</a></li>
<li><a class="" href="mocne-prawo-wielkich-liczb.html"><span class="header-section-number">20</span> Mocne prawo wielkich liczb</a></li>
<li><a class="" href="zastosowania-mpwl.html"><span class="header-section-number">21</span> Zastosowania MPWL</a></li>
<li><a class="active" href="dygresja-kompresja.html"><span class="header-section-number">22</span> Dygresja: kompresja</a></li>
<li><a class="" href="twierdzenie-de-moivrea-laplacea.html"><span class="header-section-number">23</span> Twierdzenie de Moivre’a-Laplace’a</a></li>
<li><a class="" href="zbie%C5%BCno%C5%9B%C4%87-wed%C5%82ug-rozk%C5%82adu.html"><span class="header-section-number">24</span> Zbieżność według rozkładu</a></li>
<li class="book-part">Listy zadań</li>
<li><a class="" href="lista-1-rozgrzewka.html">Lista 1: Rozgrzewka</a></li>
<li><a class="" href="lista-2-aksjomaty-rachunku-prawdopodobie%C5%84stwa.html">Lista 2: Aksjomaty rachunku prawdopodobieństwa</a></li>
<li><a class="" href="lista-3-prawdopodobie%C5%84stwo-warunkowe.html">Lista 3: Prawdopodobieństwo warunkowe</a></li>
<li><a class="" href="lista-4-niezale%C5%BCno%C5%9B%C4%87-i-lemat-borela-cantellego.html">Lista 4: Niezależność i lemat Borela-Cantellego</a></li>
<li><a class="" href="lista-5-zmienne-losowe.html">Lista 5: Zmienne losowe</a></li>
<li><a class="" href="lista-6-warto%C5%9B%C4%87-oczekiwana.html">Lista 6: Wartość oczekiwana</a></li>
<li><a class="" href="lista-7-powt%C3%B3rka-przed-kolokwium.html">Lista 7: Powtórka przed kolokwium</a></li>
<li><a class="" href="lista-8-wektory-losowe.html">Lista 8: wektory losowe</a></li>
<li><a class="" href="lista-9-niezale%C5%BCne-zmienne.html">Lista 9: Niezależne zmienne</a></li>
<li><a class="" href="lista-10-wariancja.html">Lista 10: Wariancja</a></li>
<li><a class="" href="lista-11-momenty-wielowymiarowe-i-nier%C3%B3wno%C5%9Bci.html">Lista 11: Momenty wielowymiarowe i nierówności</a></li>
<li><a class="" href="lista-12-zbie%C5%BCno%C5%9B%C4%87.html">Lista 12: Zbieżność</a></li>
<li><a class="" href="lista-13-s%C5%82aba-zbie%C5%BCno%C5%9B%C4%87.html">Lista 13: Słaba zbieżność</a></li>
<li><a class="" href="lista-14-powt%C3%B3rka-przed-kolokwium.html">Lista 14: Powtórka przed kolokwium</a></li>
<li class="book-part">Dodatek</li>
<li><a class="" href="twierdzenie-fubiniego.html">Twierdzenie Fubiniego</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="dygresja-kompresja" class="section level1" number="22">
<h1>
<span class="header-section-number">22</span> Dygresja: kompresja<a class="anchor" aria-label="anchor" href="#dygresja-kompresja"><i class="fas fa-link"></i></a>
</h1>
<div id="wprowadzenie-1" class="section level2" number="22.1">
<h2>
<span class="header-section-number">22.1</span> Wprowadzenie<a class="anchor" aria-label="anchor" href="#wprowadzenie-1"><i class="fas fa-link"></i></a>
</h2>
<p>Załóżmy, że dysponujemy następującym słownikiem
<span class="math display">\[\begin{equation*}
    \mathcal{A} = \{a,b,c,d,e,f,g,h\}.
\end{equation*}\]</span>
Wówczas każdą wiadomość złożoną z jednego słowa możemy zakodować za pomocą trzech bitów.</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th>x</th>
<th>a</th>
<th>b</th>
<th>c</th>
<th>d</th>
<th>e</th>
<th>f</th>
<th>g</th>
<th>h</th>
</tr></thead>
<tbody><tr class="odd">
<td>c(x)</td>
<td>000</td>
<td>001</td>
<td>010</td>
<td>011</td>
<td>100</td>
<td>101</td>
<td>110</td>
<td>111</td>
</tr></tbody>
</table></div>
<p>Podobnie, każdą wiadomość składającą się z <span class="math inline">\(N \in \mathbb{N}\)</span> słów możemy zakodować za pomocą <span class="math inline">\(3N\)</span> bitów.
Załóżmy, że każde słowo pojawia się z pewnym prawdopodobieństwem</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th>x</th>
<th>a</th>
<th>b</th>
<th>c</th>
<th>d</th>
<th>e</th>
<th>f</th>
<th>g</th>
<th>h</th>
</tr></thead>
<tbody><tr class="odd">
<td>P(x)</td>
<td>1/4</td>
<td>1/4</td>
<td>1/4</td>
<td>3/64</td>
<td>1/64</td>
<td>1/64</td>
<td>1/64</td>
<td>1/64</td>
</tr></tbody>
</table></div>
<p>Wówczas
<span class="math display">\[\begin{equation*}
    \mathbb{P}[a,b,c,d]=15/16.
\end{equation*}\]</span>
Jeśli jesteśmy gotowi zaryzykować, to możemy zakodować słowa za pomocą dwóch bitów</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th>x</th>
<th>a</th>
<th>b</th>
<th>c</th>
<th>d</th>
<th>e</th>
<th>f</th>
<th>g</th>
<th>h</th>
</tr></thead>
<tbody><tr class="odd">
<td>c(x)</td>
<td>00</td>
<td>01</td>
<td>10</td>
<td>11</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr></tbody>
</table></div>
<p>Wówczas z prawdopodobieństwem <span class="math inline">\(15/16\)</span> jesteśmy w stanie poprawnie zakodować wiadomość.
Prawdopodobieństwo, że wiadomość składająca się z jednego słowa nie zostanie odczytana wynosi <span class="math inline">\(1/16\)</span>.</p>
</div>
<div id="długie-wiadomości" class="section level2" number="22.2">
<h2>
<span class="header-section-number">22.2</span> Długie wiadomości<a class="anchor" aria-label="anchor" href="#d%C5%82ugie-wiadomo%C5%9Bci"><i class="fas fa-link"></i></a>
</h2>
<p>Chcemy teraz kodować długie wiadomości. Niech <span class="math inline">\(M \in \mathbb{N}\)</span>. Zakładać będziemy, że nasz słownik jest postaci
<span class="math inline">\(\mathcal{A} = \{1,2, \ldots , M\} = [M]\)</span>. Dla <span class="math inline">\(j \in \mathbb{N}\)</span> niech <span class="math inline">\(X_j\)</span> będzie <span class="math inline">\(j\)</span>-tym słowem losowej wiadomości.
Zakładać będziemy, że zmienne <span class="math inline">\(\{X_j\}_{j \in \mathbb{N}}\)</span> są niezależne
z rozkładem
<span class="math display">\[\begin{equation*}
    \mathbb{P}[X_j=k] = p_k
\end{equation*}\]</span>
dla pewnych liczb <span class="math inline">\(p_k \in [0,1]\)</span> takich, że <span class="math inline">\(\sum_{k=1}^Mp_k =1\)</span>.
Niech <span class="math inline">\(N \in \mathbb{N}\)</span>. <span class="math inline">\(N\)</span>-wymiarowy wektor losowy <span class="math inline">\(\vec{X} = (X_1, X_2, \ldots, X_N)\)</span> jest internującą
nas wiadomością, którą chcemy zakodować (zapisać) za pomocą możliwie małej liczby bitów.</p>
<p>Jeżeli <span class="math inline">\(\vec{a} = (a_1, \ldots, a_N)\)</span> jest typową wiadomością, to spodziewamy się, że
<span class="math display">\[\begin{equation*}
\mathrm{P}(\vec{a}) = \mathbb{P}\left[\vec{X}=\vec{a}\right] = p_{a_1}p_{a_2}\cdots p_{a_N} \sim p_1^{p_1N} \cdot p_2^{p_2N} \cdots p_M^{p_MN}
\end{equation*}\]</span>
Zatem
<span class="math display">\[\begin{equation*}
    \log_2\left(1/\mathrm{P}(\vec{a}) \right) \sim N \sum_{k=1}^M p_k\log_2(1/p_k).
\end{equation*}\]</span>
Liczbę
<span class="math display">\[\begin{equation*}
    H= \sum_{k=1}^M p_k\log(1/p_k)
\end{equation*}\]</span>
nazywamy entropią rozkładu <span class="math inline">\((p_1, \ldots, p_M)\)</span>. Dla <span class="math inline">\(\epsilon&gt;0\)</span> rozważmy zbiór
<span class="math display">\[\begin{equation*}
    T_{N,\epsilon} = \left\{ \vec{a} \in \mathcal{A}^N \: :\: \left| \frac 1N \log_2 (1/\mathrm{P}(\vec{a})) -H \right| &lt;\epsilon \right\}
\end{equation*}\]</span>
tych słów długości <span class="math inline">\(N\)</span>, których prawdopodobieństwo jest między <span class="math inline">\(2^{-N(H+\epsilon)}\)</span> a <span class="math inline">\(2^{-N(H-\epsilon)}\)</span>.
Okazuje się, że typowe wiadomości są w <span class="math inline">\(T_{N,\epsilon}\)</span>. Rzeczywiście <span class="math inline">\(\vec{X} \in T_{N,\epsilon}\)</span> wtedy i tylko wtedy, gdy
<span class="math display">\[\begin{equation*}
    \left| \frac 1N \log_2 (1/\mathrm{P}(\vec{X})) -H \right| &lt;\epsilon.
\end{equation*}\]</span>
Zauważmy, że
<span class="math display">\[\begin{equation*}
    \frac 1N \log_2 (1/\mathrm{P}(\vec{X})) = \frac 1N \log_2 \left( \frac 1{p_{X_1}p_{X_2}\cdots p_{X_N} } \right)
= \frac 1N\sum_{k=1}^N \log_2(1/p_{X_j}).
\end{equation*}\]</span>
Korzystając z Mocnego prawa wielkich liczb
<span class="math display">\[\begin{equation*}
   \frac 1N\sum_{k=1}^N \log_2(1/p_{X_j}) \to \mathbb{E}\left[ \log_2(1/p_{X_1}) \right]
\end{equation*}\]</span>
prawie na pewno. Mamy
<span class="math display">\[\begin{equation*}
    \mathbb{E}\left[ \log_2(1/p_{X_1}) \right] = \sum_{k=1}^M \mathbb{P}[X_1=k] \log_2(1/p_{k}) = \sum_{k=1}^M p_k\log_2(1/p_k) = H.
\end{equation*}\]</span>
Podsumowując, z prawdopodobieństwem jeden
<span class="math display">\[\begin{equation*}
    \frac 1N \log_2 (1/\mathrm{P}(\vec{X})) \to H.
\end{equation*}\]</span>
Zauważmy, że
<span class="math display">\[\begin{equation*}
1 \geq \mathbb{P}\left[ \vec{X} \in T_{N, \epsilon} \right] = \sum_{\vec{a} \in T_{N,\epsilon}} \mathrm{P}(\vec{a})
\geq 2^{-N(H+\epsilon)} \left|T_{N,\epsilon}\right|.
\end{equation*}\]</span>
Stąd
<span class="math display">\[\begin{equation*}
    \left| T_{N,\epsilon} \right| \leq 2^{N(H+\epsilon)}.
\end{equation*}\]</span>
Do zakodowania typowej wiadomości potrzebujemy więc <span class="math inline">\(N(H+\epsilon)\)</span> bitów. Zauważmy, że z nierówności Jensena
<span class="math display">\[\begin{equation*}
    H = \sum_{k=1}^M p_k \log_2(1/p_k) \leq \log_2 \left(\sum_{k=1}^M 1 \right) = \log_2(M).
\end{equation*}\]</span>
Przy czym równość zachodzi jedynie w przypadku <span class="math inline">\(p_k=1/M\)</span>.
Jeżeli więc rozkład <span class="math inline">\((p_1, \ldots , p_M)\)</span> nie jest jednostajny, to
<span class="math inline">\(H&lt;\log_2(M)\)</span>. Wówczas dla dostatecznie małego <span class="math inline">\(\epsilon&gt;0\)</span>, <span class="math inline">\(H+\epsilon&lt; \log_2(M)\)</span>. Wtedy
<span class="math display">\[2^{N(H+\epsilon)} \ll 2^{N\log_2(M)} = \left|\mathcal{A}^N \right|. \]</span>
Z prawdopodobieństwem bliskim jeden, każdą wiadomość długości <span class="math inline">\(N\)</span> jesteśmy w stanie zapisać za pomocą
<span class="math inline">\(N(H+\epsilon)\)</span> bitów. Skoro <span class="math inline">\(H+\epsilon&lt;\log_2(M)\)</span> oznacza to, że jesteśmy w stanie skompresować dane.</p>
<p>Można pokazać, że <span class="math inline">\(H\)</span> jest optymalne. Dokładniej nie jest możliwa kompresja do <span class="math inline">\(N(H-\epsilon)\)</span> bitów. Wówczas
prawdopodobieństwo poprawnego odczytania wiadomości jest oddalone od jeden.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="zastosowania-mpwl.html"><span class="header-section-number">21</span> Zastosowania MPWL</a></div>
<div class="next"><a href="twierdzenie-de-moivrea-laplacea.html"><span class="header-section-number">23</span> Twierdzenie de Moivre’a-Laplace’a</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#dygresja-kompresja"><span class="header-section-number">22</span> Dygresja: kompresja</a></li>
<li><a class="nav-link" href="#wprowadzenie-1"><span class="header-section-number">22.1</span> Wprowadzenie</a></li>
<li><a class="nav-link" href="#d%C5%82ugie-wiadomo%C5%9Bci"><span class="header-section-number">22.2</span> Długie wiadomości</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Rachunek Prawdopodobieństwa 1R</strong>: Notatki do wykładu" was written by Dariusz Buraczewski, Piotr Dyszewski. It was last built on 2025-05-27.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
